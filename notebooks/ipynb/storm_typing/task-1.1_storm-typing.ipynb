{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<script>\n",
       "\n",
       "code_show=true; \n",
       "\n",
       "function code_toggle() {\n",
       "if (code_show){\n",
       "$('div.input').hide();\n",
       "    if (document.getElementById('input') !== null)\n",
       "        {document.getElementById('input').value = 'Display code in notebook';}\n",
       "} else {\n",
       "$('div.input').not(':first').show();\n",
       "document.getElementById('input').value = 'Hide code in notebook';\n",
       "}\n",
       "code_show = !code_show\n",
       "}\n",
       "\n",
       "$( document ).ready(code_toggle);\n",
       "$('div.cell.code_cell.rendered.selected').find('div.input').hide();\n",
       "\n",
       "\n",
       "\n",
       "</script>\n",
       "\n",
       "<form id=\"form\" action=\"javascript:code_toggle()\">\n",
       "    <input id=\"input\" type=\"submit\" value=\"Display code in notebook\">\n",
       "</form>\n",
       "\n",
       "\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import HTML\n",
    "\n",
    "HTML('''<script>\n",
    "\n",
    "code_show=true; \n",
    "\n",
    "function code_toggle() {\n",
    "if (code_show){\n",
    "$('div.input').hide();\n",
    "    if (document.getElementById('input') !== null)\n",
    "        {document.getElementById('input').value = 'Display code in notebook';}\n",
    "} else {\n",
    "$('div.input').not(':first').show();\n",
    "document.getElementById('input').value = 'Hide code in notebook';\n",
    "}\n",
    "code_show = !code_show\n",
    "}\n",
    "\n",
    "$( document ).ready(code_toggle);\n",
    "$('div.cell.code_cell.rendered.selected').find('div.input').hide();\n",
    "\n",
    "\n",
    "\n",
    "</script>\n",
    "\n",
    "<form id=\"form\" action=\"javascript:code_toggle()\">\n",
    "    <input id=\"input\" type=\"submit\" value=\"Display code in notebook\">\n",
    "</form>\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask.dataframe as dd\n",
    "import os\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from dask.distributed import Client\n",
    "import plotly.graph_objects as go\n",
    "import geopandas as gpd\n",
    "import plotly.express as px\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "import hvplot.pandas\n",
    "import sys\n",
    "from io import StringIO\n",
    "import requests\n",
    "import xarray as xr\n",
    "import warnings\n",
    "\n",
    "pd.set_option('display.max_rows', 2000)\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Local functions\n",
    "import sefm.backends.climate.storm_typing as clim\n",
    "import sefm.utils.hydrotools as ht"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Usage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Storm typing classifies storms events into classes that are nearly homogeneous with respects to their generating phenomenon. This allows to evaluate more homogeunous distributions for each storm type when computing precipitation-frequency analysis rather than a traditionel mixed distribution with all the storms. Homogeneity is an assumption when computing frequency analysis which makes storm typing all the more important."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Storm types"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Description ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Database of Daily Storm Types (DDST)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Description ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Calculations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Introduction..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![alt text](https://s3.us-east-2.wasabisys.com/analytics-store/img/AMS.png?raw=true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Intrants"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Définition d'une région spatiale afin de limiter l'extraction des données météos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Markdown as md\n",
    "\n",
    "md(\"Définition d'une région spatiale afin de limiter l'extraction des données météos = %s\"%(str(latlngbox)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "latlngbox = [-82, -74, 44.5, 49]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Définition des caracrétistiques du stockage des données de stations météorologiques (GHCN-D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bucket = 's3://ghcnd-can-us-ne'\n",
    "storage_options={'anon': True,\n",
    "                 \"client_kwargs\": {'endpoint_url': 'https://s3.us-east-2.wasabisys.com'}}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Client Dask "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le client Dask permet de paralléliser l'ensemble du code ci-après et d'effectuer le calcul par lazy loading. Lorsqu'un calcul est lancé, celui-ci peut être suivi en temps réel via le tableau de bord (dashboard) dont l'adresse est affichée ci-dessous."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = Client()\n",
    "client"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importation des stations météorologiques (GHCN-D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "st = clim.Stations(metadata_bucket=os.path.join(bucket,'ghcdn_stations.csv'),\n",
    "                   storage_options=storage_options)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importation des métadonnées"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les métadonnées sont filtrés via les limites géographiques définies dans la variable <em>latlngbox</em>\n",
    "Notons que les métadonnées peuvent également être filtrées à l'aide du ou des numéros de stations.\n",
    "\n",
    "Exemple: *st.read_metadata(station_names=['CA007038080',...])*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "st.read_metadata(latlngbox=latlngbox)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importation des données"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les données sont acquises via *lazy loading* à partir du format parquet afin de profiter de l'indexation des séries temporelles et ramener les données plus rapidement pour réaliser le calcul"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = st.read_parquet(os.path.join(bucket,'data/parquet/data.parquet'),\n",
    "                     element='PRCP',\n",
    "                     storage_options=storage_options)\n",
    "df['value'] = df['value']/10.0 # Pour convertir vers mm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transformation des données"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pivot des données"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les données sont pivotées à l'aide de l'index (numéro de station) afin d'obtenir une colonne de séries temporelles par station. Pour avoir suffisamment de données de qualité, seules les données après 1900 sont retenues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pivot = df.pivot_table(index='date', columns='id', values='value')\n",
    "df_pivot.index = pd.to_datetime(df_pivot.index)\n",
    "\n",
    "df_pivot = df_pivot[df_pivot.index.year>=1900]\n",
    "df_pivot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FROM THIS POINT ON, THIS IS A WORK IN PROGRESS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf_outaouais = gpd.read_file('/home/slanglois/PycharmProjects/DEMv2/data/Bassins Outaouais HSAMI.geojson')\n",
    "ddst.visualisation_stations(gdf_outaouais, \n",
    "                            df_stations,\n",
    "                            latlngbox)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "store = os.path.join(data_path,\n",
    "                     'data/reanalysis/CIRES_20_Century_Reanalysis/3h/single-levels/zarr')\n",
    "ds = xr.open_zarr(store=store,\n",
    "                  consolidated=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zones_path = '/media/slanglois/ssd-2tb/sefm/data/gis/AMS.shp'\n",
    "gdf = gpd.read_file(zones_path)\n",
    "gdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cape = ht.clip_polygon_to_dataframe(dataset=ds,\n",
    "                                       geodataframe=gdf.sort_values(by='id'),\n",
    "                                       geodf_index_column='id',\n",
    "                                       variable='cape',  \n",
    "                                       aggregation='mean',\n",
    "                                       resample_time='1D', # originalement au pas de temps horaire\n",
    "                                       from_tz='UTC',\n",
    "                                       to_tz='America/Montreal',\n",
    "                                       latlng_names=['latitude',\n",
    "                                                    'longitude']\n",
    "                                       )\n",
    "\n",
    "df_cape.columns = ['Cape1', 'Cape2', 'Cape3', 'Cape4']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pr_wtr=ht.clip_polygon_to_dataframe(dataset=ds,\n",
    "                                       geodataframe=gdf.sort_values(by='id'),\n",
    "                                       geodf_index_column='id',\n",
    "                                       variable='pr_wtr',  \n",
    "                                       aggregation='sum',\n",
    "                                       resample_time='1D', # originalement au pas de temps horaire\n",
    "                                       from_tz='UTC',\n",
    "                                       to_tz='America/Montreal',\n",
    "                                       latlng_names=['latitude',\n",
    "                                                    'longitude']\n",
    "                                       )\n",
    "df_pr_wtr.columns = ['Pw1', 'Pw2', 'Pw3', 'Pw4']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_stations_complet = df_stations[df_stations['id'].isin(df['id'].unique())]\n",
    "gdf_stations = gpd.GeoDataFrame(df_stations_complet, geometry=gpd.points_from_xy(df_stations_complet.longitude,\n",
    "                                                                                 df_stations_complet.latitude))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.read_csv('/media/slanglois/ssd-2tb/sefm/data/observations/HQP/liste_stations_HQP.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf_stations2 = gpd.GeoDataFrame(df2, geometry=gpd.points_from_xy(df2.xcoord, df2.ycoord))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ams4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ams1=gdf_stations2[gdf_stations2.within(gdf.iloc[0].geometry)].NOM_DETAILLE\n",
    "ams2=gdf_stations2[gdf_stations2.within(gdf.iloc[1].geometry)].NOM_DETAILLE\n",
    "ams3=gdf_stations2[gdf_stations2.within(gdf.iloc[2].geometry)].NOM_DETAILLE\n",
    "ams4=gdf_stations2[gdf_stations2.within(gdf.iloc[3].geometry)].NOM_DETAILLE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ams1=gdf_stations[gdf_stations.within(gdf.iloc[0].geometry)].id\n",
    "ams2=gdf_stations[gdf_stations.within(gdf.iloc[1].geometry)].id\n",
    "ams3=gdf_stations[gdf_stations.within(gdf.iloc[2].geometry)].id\n",
    "ams4=gdf_stations[gdf_stations.within(gdf.iloc[3].geometry)].id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# recalculer le ratio pour les 4 zones de l'Outaouais ?\n",
    "\n",
    "def rain_is_significant(row):\n",
    "    return row[row>1.27].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rain_sta_ratio = df_stations_precip.apply(lambda row: rain_is_significant(row), \n",
    "#                                           axis=1)/df_stations_precip.count(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rain_sta_ratio_asm1 = df_stations_precip[ams1].apply(lambda row: rain_is_significant(row), \n",
    "                                               axis=1)/df_stations_precip[ams1].count(axis=1)\n",
    "\n",
    "rain_sta_ratio_asm2 = df_stations_precip[ams2].apply(lambda row: rain_is_significant(row), \n",
    "                                               axis=1)/df_stations_precip[ams2].count(axis=1)\n",
    "\n",
    "rain_sta_ratio_asm3 = df_stations_precip[ams3].apply(lambda row: rain_is_significant(row), \n",
    "                                               axis=1)/df_stations_precip[ams3].count(axis=1)\n",
    "\n",
    "rain_sta_ratio_asm4 = df_stations_precip[ams4].apply(lambda row: rain_is_significant(row), \n",
    "                                               axis=1)/df_stations_precip[ams4].count(axis=1)\n",
    "\n",
    "rain_sta_ratio = pd.concat([rain_sta_ratio_asm1, rain_sta_ratio_asm2,\n",
    "                           rain_sta_ratio_asm3, rain_sta_ratio_asm4], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rain_sta_ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_stations_precip[ams2].count(axis=1).plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ddst = pd.concat([rain_sta_ratio, df_pr_wtr, df_cape], axis=1)\n",
    "ddst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rain_sta_ratio.hvplot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(df_stations_precip.count(axis=1).rolling(1000).mean()).hvplot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rain_sta_ratio.rolling(1000).mean().hvplot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sefm",
   "language": "python",
   "name": "sefm"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
